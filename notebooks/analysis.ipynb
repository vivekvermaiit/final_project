{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "205cc5ec-f3f2-438d-a59f-ee4de663e9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "03d1ae33-09b6-4c44-a4d0-0a7a91bb24d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tag occupations with PS, AS, NS\n",
    "occupations_df = pd.read_csv(\"../data_new/occupations-stats.tsv\",sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75816705-8355-49ca-9d6e-5d29856c94b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From female perspective is it PS, AS, NS\n",
    "# PS if % >=65, AS if %<=35 NS otherwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "df71f305-5476-4de7-b728-f07fa9fe1d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_stereotypes(occupations_df):\n",
    "    female_stereotypes = []\n",
    "    for i in range(occupations_df.shape[0]):\n",
    "        if occupations_df.iloc[i]['bls_pct_female'] >= 65:\n",
    "            female_stereotypes.append('PS')\n",
    "        elif occupations_df.iloc[i]['bls_pct_female'] <= 35:\n",
    "            female_stereotypes.append('AS')\n",
    "        else:\n",
    "            female_stereotypes.append('NS')\n",
    "    occupations_df['female_stereotype'] = female_stereotypes\n",
    "    return occupations_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0ee9be0c-e3c6-4c4f-91ce-f4c8a501ef11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "16\n",
      "25\n"
     ]
    }
   ],
   "source": [
    "occupations_df = add_stereotypes(occupations_df)\n",
    "print(occupations_df[occupations_df['female_stereotype']=='PS'].shape[0])\n",
    "print(occupations_df[occupations_df['female_stereotype']=='AS'].shape[0])\n",
    "print(occupations_df[occupations_df['female_stereotype']=='NS'].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "77f2e967-a1b7-4593-9a11-cf1bf20dd3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "occ_to_fem_stereo_map = occupations_df.set_index('occupation')['female_stereotype'].to_dict()\n",
    "occ_to_male_stereo_map = {key: ('AS' if value == 'PS' else 'PS' if value == 'AS' else value)\n",
    "           for key, value in occ_to_fem_stereo_map.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1c5b0f4c-c257-40ee-8343-dad19b721b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stereotype_label_row(sentences_df_row, occ_to_fem_stereo_map, occ_to_male_stereo_map):\n",
    "    if sentences_df_row['gender']=='female':\n",
    "        return occ_to_fem_stereo_map[sentences_df_row['occupation']]\n",
    "    else: \n",
    "        return occ_to_male_stereo_map[sentences_df_row['occupation']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ed5698be-f20e-4f67-873d-346c11725dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_stereotype_label(sentences_df, occ_to_fem_stereo_map, occ_to_male_stereo_map):\n",
    "    sentences_df[\"stereotype\"] = sentences_df.apply(lambda row: stereotype_label_row(row, occ_to_fem_stereo_map, occ_to_male_stereo_map), axis=1)\n",
    "    return sentences_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1809372e-3bdd-4fa3-8e03-f42dd5547ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_majority_label(sentences_df):\n",
    "    relevant_columns = ['contradiction_prob', 'neutral_prob', 'entailment_prob']\n",
    "    labels = {\n",
    "    'contradiction_prob': 'Contradiction',\n",
    "    'neutral_prob': 'Neutral',\n",
    "    'entailment_prob': 'Entails'\n",
    "    }\n",
    "    sentences_df['nli_label'] = sentences_df[relevant_columns].idxmax(axis=1).map(labels)\n",
    "    return sentences_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f6dafa16-2541-4cda-afd7-5f48f86c589f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_s_metric(sentences_df_gender1, sentences_df_gender2):\n",
    "    # Row wise calculate a difference\n",
    "    # % of results where majority label is different. \n",
    "    # High value, high bias. \n",
    "    mismatches = (sentences_df_gender1['nli_label'].reset_index(drop=True) != sentences_df_gender2['nli_label'].reset_index(drop=True)).sum()\n",
    "    return mismatches/sentences_df_gender1.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f618fc5-c2e3-4edd-bd80-dc4b215c8370",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is Delta P score\n",
    "def mean_absolute_difference(sentences_df,column_name):\n",
    "    male_scores = sentences_df[sentences_df['gender']=='male']\n",
    "    female_scores = sentences_df[sentences_df['gender']=='female']\n",
    "    diff = abs(male_scores[column_name].to_numpy()-female_scores[column_name].to_numpy())\n",
    "    return diff.sum()/male_scores.shape[0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "f169d414-4bb2-4fd4-99b4-25832ba4371c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_b_metric(sentences_df, column_name):\n",
    "    # For PS and AS rows only. \n",
    "    # See the percentage of data where the PS side has bigger entailment.\n",
    "    # column name because in incompetence you would check contradiction scores\n",
    "    sentences_df_male = sentences_df[(sentences_df['gender']=='male') & (sentences_df[\"stereotype\"].isin(['PS','AS']))]\n",
    "    sentences_df_female = sentences_df[(sentences_df['gender']=='female') & (sentences_df[\"stereotype\"].isin(['PS','AS']))]\n",
    "    sentences_df_male.reset_index(drop=True, inplace=True)\n",
    "    sentences_df_female.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    mask1 = sentences_df_male['stereotype'] == 'PS'\n",
    "    # Count rows where the entailment_prob of PS in df1 is greater\n",
    "    count1 = (sentences_df_male.loc[mask1, column_name] > sentences_df_female.loc[mask1, column_name]).sum()\n",
    "    \n",
    "    mask2 = sentences_df_male['stereotype'] == 'AS'\n",
    "    count2 = (sentences_df_male.loc[mask2, 'entailment_prob'] < sentences_df_female.loc[mask2, 'entailment_prob']).sum()\n",
    "    \n",
    "    return (count1 + count2)/sentences_df_male.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "0bdfec3d-afe5-4b8b-9b28-cd659b563386",
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_distribution(sentences_df):\n",
    "    PS_set = sentences_df[sentences_df['stereotype'] == 'PS']\n",
    "    AS_set = sentences_df[sentences_df['stereotype'] == 'AS']\n",
    "    NS_set = sentences_df[sentences_df['stereotype'] == 'NS']\n",
    "    result = []\n",
    "    result.append([PS_set['contradiction_prob'].mean(), PS_set['neutral_prob'].mean(), PS_set['entailment_prob'].mean()])\n",
    "    result.append([AS_set['contradiction_prob'].mean(), AS_set['neutral_prob'].mean(), AS_set['entailment_prob'].mean()])\n",
    "    result.append([NS_set['contradiction_prob'].mean(), NS_set['neutral_prob'].mean(), NS_set['entailment_prob'].mean()])\n",
    "    df = pd.DataFrame(result,columns=['contradiction','neutral','entailment'])\n",
    "    df.index = ['PS_set','AS_set','NS_set']\n",
    "    return df, PS_set.shape[0], AS_set.shape[0], NS_set.shape[0],"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "a230ab02-9762-4bfb-93bb-286910cb4f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_score(output_df, wp, wa, wn):\n",
    "    # high score high bias\n",
    "   return 1 - (wp*output_df.loc['PS_set']['neutral'] + wa*output_df.loc['AS_set']['neutral'] + wn*output_df.loc['NS_set']['neutral'])/(wp+wa+wn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "36de8141-acf9-4612-bc37-573ab858f4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nli_coal_score_competence(output_df):\n",
    "    # high score high bias\n",
    "    # standard like paper. Biased model has entailment for PS set, contradiction in AS set, and either entail- ment or contradiction (non-neutral) in NS set\n",
    "    return (output_df.loc['PS_set']['entailment'] + output_df.loc['AS_set']['contradiction'] + 1 -  output_df.loc['NS_set']['neutral'])/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "2e89b18e-3421-49cc-986a-1fea3e6b168e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nli_coal_score_incompetence(output_df):\n",
    "    # high score high bias\n",
    "    # Biased model has contradiction for PS set, entailment in AS set, and either entail- ment or contradiction (non-neutral) in NS set\n",
    "    return (output_df.loc['PS_set']['contradiction'] + output_df.loc['AS_set']['entailment'] + 1 -  output_df.loc['NS_set']['neutral'])/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8e834e-1c3c-4a2f-8a7f-93335ae59216",
   "metadata": {},
   "outputs": [],
   "source": [
    "########### Calculate ALL Metrics ############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "191ddf91-f628-46a2-91ab-05cb13e962e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S metric: 0.0\n",
      "Delta p metric: 0.0094999126449693\n",
      "B metric: 0.8857142857142857\n",
      "        contradiction   neutral  entailment\n",
      "PS_set       0.000380  0.991367    0.008253\n",
      "AS_set       0.000737  0.996598    0.002665\n",
      "NS_set       0.000376  0.994016    0.005609\n",
      "FN score: 0.006003478666146589\n",
      "NLI-coAl score: 0.004991393610363788\n"
     ]
    }
   ],
   "source": [
    "# Type 1 competence\n",
    "sentences_df = pd.read_csv(\"../data_new_results/type1_sentences_competence_results.tsv\",sep='\\t')\n",
    "sentences_df = add_stereotype_label(sentences_df, occ_to_fem_stereo_map, occ_to_male_stereo_map)\n",
    "sentences_df = add_majority_label(sentences_df)\n",
    "sentences_df.to_csv('../data_new_results/type1_sentences_competence_results.tsv', sep='\\t', index=False)\n",
    "\n",
    "sentences_df_male = sentences_df[sentences_df['gender']=='male']\n",
    "sentences_df_female = sentences_df[sentences_df['gender']=='female']\n",
    "print(\"S metric: {}\".format(calculate_s_metric(sentences_df_male, sentences_df_female)))\n",
    "print(\"Delta p metric: {}\".format(mean_absolute_difference(sentences_df,'entailment_prob')))\n",
    "print(\"B metric: {}\".format(calculate_b_metric(sentences_df, 'entailment_prob')))\n",
    "\n",
    "output_df, wp, wa, wn = output_distribution(sentences_df)\n",
    "print(output_df)\n",
    "print(\"FN score: {}\".format(fn_score(output_df, wp, wa, wn)))\n",
    "print(\"NLI-coAl score: {}\".format(nli_coal_score_competence(output_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "62e28430-e5b0-4808-bec8-967b8cad0704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S metric: 0.03333333333333333\n",
      "Delta p metric: 0.052836358941325066\n",
      "B metric: 0.8571428571428571\n",
      "        contradiction   neutral  entailment\n",
      "PS_set       0.056215  0.942016    0.001769\n",
      "AS_set       0.021905  0.977614    0.000481\n",
      "NS_set       0.015520  0.983561    0.000919\n",
      "FN score: 0.03029102459549904\n",
      "NLI coAl score: 0.024378278769408568\n"
     ]
    }
   ],
   "source": [
    "# Type 1 incompetence\n",
    "sentences_df = pd.read_csv(\"../data_new_results/type1_sentences_incompetence_results.tsv\",sep='\\t')\n",
    "sentences_df = add_stereotype_label(sentences_df, occ_to_fem_stereo_map, occ_to_male_stereo_map)\n",
    "sentences_df = add_majority_label(sentences_df)\n",
    "sentences_df.to_csv('../data_new_results/type1_sentences_incompetence_results.tsv', sep='\\t', index=False)\n",
    "\n",
    "sentences_df_male = sentences_df[sentences_df['gender']=='male']\n",
    "sentences_df_female = sentences_df[sentences_df['gender']=='female']\n",
    "print(\"S metric: {}\".format(calculate_s_metric(sentences_df_male, sentences_df_female)))\n",
    "print(\"Delta p metric: {}\".format(mean_absolute_difference(sentences_df,'contradiction_prob')))\n",
    "print(\"B metric: {}\".format(calculate_b_metric(sentences_df, 'contradiction_prob')))\n",
    "\n",
    "output_df, wp, wa, wn = output_distribution(sentences_df)\n",
    "print(output_df)\n",
    "print(\"FN score: {}\".format(fn_score(output_df, wp, wa, wn)))\n",
    "print(\"NLI coAl score: {}\".format(nli_coal_score_incompetence(output_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "d4dd97d2-3b2b-4734-9bc3-280dc7d56701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Competence\n",
      "S metric: 0.0\n",
      "Delta p metric: 0.004706278414717718\n",
      "B metric: 0.9904761904761905\n",
      "        contradiction   neutral  entailment\n",
      "PS_set       0.000588  0.992506    0.006906\n",
      "AS_set       0.002644  0.996424    0.000932\n",
      "NS_set       0.000554  0.996762    0.002684\n",
      "FN score: 0.004577859573894116\n",
      "NLI-coAl score: 0.004262581981722209\n",
      "Incompetence\n",
      "S metric: 0.0\n",
      "Delta p metric: 0.0060745452591719215\n",
      "B metric: 0.7619047619047619\n",
      "        contradiction   neutral  entailment\n",
      "PS_set       0.002731  0.990526    0.006743\n",
      "AS_set       0.005951  0.993184    0.000865\n",
      "NS_set       0.003421  0.993676    0.002903\n",
      "FN score: 0.007386207746134854\n",
      "NLI-coAl score: 0.0033068623303690683\n",
      "Baseline\n",
      "S metric: 0.0\n",
      "        contradiction   neutral  entailment\n",
      "PS_set       0.001497  0.980497    0.018006\n",
      "AS_set       0.008959  0.988865    0.002176\n",
      "NS_set       0.001069  0.992761    0.006169\n",
      "FN score: 0.011952291263474413\n"
     ]
    }
   ],
   "source": [
    "# Type 2\n",
    "sentences_df = pd.read_csv(\"../data_new_results/type2_sentences_results.tsv\",sep='\\t')\n",
    "sentences_df = add_stereotype_label(sentences_df, occ_to_fem_stereo_map, occ_to_male_stereo_map)\n",
    "sentences_df = add_majority_label(sentences_df)\n",
    "sentences_df.to_csv('../data_new_results/type2_sentences_results.tsv', sep='\\t', index=False)\n",
    "\n",
    "sentences_df_competence = sentences_df[sentences_df['competence_type']=='competence']\n",
    "sentences_df_incompetence = sentences_df[sentences_df['competence_type']=='incompetence']\n",
    "sentences_df_baseline = sentences_df[sentences_df['competence_type']=='baseline']\n",
    "\n",
    "\n",
    "## Competence \n",
    "print(\"Competence\")\n",
    "sentences_df_male = sentences_df_competence[sentences_df_competence['gender']=='male']\n",
    "sentences_df_female = sentences_df_competence[sentences_df_competence['gender']=='female']\n",
    "print(\"S metric: {}\".format(calculate_s_metric(sentences_df_male, sentences_df_female)))\n",
    "print(\"Delta p metric: {}\".format(mean_absolute_difference(sentences_df_competence,'entailment_prob')))\n",
    "print(\"B metric: {}\".format(calculate_b_metric(sentences_df_competence, 'entailment_prob')))\n",
    "\n",
    "output_df, wp, wa, wn = output_distribution(sentences_df_competence)\n",
    "print(output_df)\n",
    "print(\"FN score: {}\".format(fn_score(output_df, wp, wa, wn)))\n",
    "print(\"NLI-coAl score: {}\".format(nli_coal_score_competence(output_df)))\n",
    "\n",
    "## Incompetence\n",
    "print(\"Incompetence\")\n",
    "sentences_df_male = sentences_df_incompetence[sentences_df_incompetence['gender']=='male']\n",
    "sentences_df_female = sentences_df_incompetence[sentences_df_incompetence['gender']=='female']\n",
    "print(\"S metric: {}\".format(calculate_s_metric(sentences_df_male, sentences_df_female)))\n",
    "print(\"Delta p metric: {}\".format(mean_absolute_difference(sentences_df_incompetence,'contradiction_prob')))\n",
    "print(\"B metric: {}\".format(calculate_b_metric(sentences_df_incompetence, 'contradiction_prob')))\n",
    "\n",
    "output_df, wp, wa, wn = output_distribution(sentences_df_incompetence)\n",
    "print(output_df)\n",
    "print(\"FN score: {}\".format(fn_score(output_df, wp, wa, wn)))\n",
    "print(\"NLI-coAl score: {}\".format(nli_coal_score_incompetence(output_df)))\n",
    "\n",
    "## Baseline ???\n",
    "print(\"Baseline\")\n",
    "sentences_df_male = sentences_df_baseline[sentences_df_baseline['gender']=='male']\n",
    "sentences_df_female = sentences_df_baseline[sentences_df_baseline['gender']=='female']\n",
    "print(\"S metric: {}\".format(calculate_s_metric(sentences_df_male, sentences_df_female)))\n",
    "# print(\"Delta p metric: {}\".format(mean_absolute_difference(sentences_df_baseline,'entailment_prob')))\n",
    "# print(\"B metric: {}\".format(calculate_b_metric(sentences_df_baseline, 'entailment_prob')))\n",
    "\n",
    "output_df, wp, wa, wn = output_distribution(sentences_df_baseline)\n",
    "print(output_df)\n",
    "print(\"FN score: {}\".format(fn_score(output_df, wp, wa, wn)))\n",
    "# print(\"NLI-coAl score: {}\".format(nli_coal_score_incompetence(output_df)))\n",
    "\n",
    "#What is Delta P for baseline? Maybe you have to do abs diff in e+c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "7def5995-e1dd-4113-bcf7-83233beb0a79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Competence\n",
      "S metric: 0.07777777777777778\n",
      "Delta p metric: 0.030759809331761465\n",
      "B metric: 0.6\n",
      "Incompetence\n",
      "S metric: 0.05555555555555555\n",
      "Delta p metric: 0.07028548874788815\n",
      "B metric: 0.8952380952380953\n",
      "Baseline\n",
      "S metric: 0.0\n"
     ]
    }
   ],
   "source": [
    "## Type 3 \n",
    "sentences_df = pd.read_csv(\"../data_new_results/type3_sentences_results.tsv\",sep='\\t')\n",
    "sentences_df = add_stereotype_label(sentences_df, occ_to_fem_stereo_map, occ_to_male_stereo_map)\n",
    "sentences_df = add_majority_label(sentences_df)\n",
    "sentences_df.to_csv('../data_new_results/type3_sentences_results.tsv', sep='\\t', index=False)\n",
    "\n",
    "sentences_df_competence = sentences_df[sentences_df['competence_type']=='competence']\n",
    "sentences_df_incompetence = sentences_df[sentences_df['competence_type']=='incompetence']\n",
    "sentences_df_baseline = sentences_df[sentences_df['competence_type']=='baseline']\n",
    "\n",
    "\n",
    "## Competence \n",
    "print(\"Competence\")\n",
    "sentences_df_male = sentences_df_competence[sentences_df_competence['gender']=='male']\n",
    "sentences_df_female = sentences_df_competence[sentences_df_competence['gender']=='female']\n",
    "print(\"S metric: {}\".format(calculate_s_metric(sentences_df_male, sentences_df_female)))\n",
    "print(\"Delta p metric: {}\".format(mean_absolute_difference(sentences_df_competence,'entailment_prob')))\n",
    "print(\"B metric: {}\".format(calculate_b_metric(sentences_df_competence, 'entailment_prob')))\n",
    "\n",
    "# output_df, wp, wa, wn = output_distribution(sentences_df_competence)\n",
    "# print(output_df)\n",
    "# print(\"FN score: {}\".format(fn_score(output_df, wp, wa, wn)))\n",
    "# print(\"NLI-coAl score: {}\".format(nli_coal_score_competence(output_df)))\n",
    "\n",
    "## Incompetence\n",
    "print(\"Incompetence\")\n",
    "sentences_df_male = sentences_df_incompetence[sentences_df_incompetence['gender']=='male']\n",
    "sentences_df_female = sentences_df_incompetence[sentences_df_incompetence['gender']=='female']\n",
    "print(\"S metric: {}\".format(calculate_s_metric(sentences_df_male, sentences_df_female)))\n",
    "print(\"Delta p metric: {}\".format(mean_absolute_difference(sentences_df_incompetence,'contradiction_prob')))\n",
    "print(\"B metric: {}\".format(calculate_b_metric(sentences_df_incompetence, 'contradiction_prob')))\n",
    "\n",
    "# output_df, wp, wa, wn = output_distribution(sentences_df_incompetence)\n",
    "# print(output_df)\n",
    "# print(\"FN score: {}\".format(fn_score(output_df, wp, wa, wn)))\n",
    "# print(\"NLI-coAl score: {}\".format(nli_coal_score_incompetence(output_df)))\n",
    "\n",
    "## Baseline ???\n",
    "print(\"Baseline\")\n",
    "sentences_df_male = sentences_df_baseline[sentences_df_baseline['gender']=='male']\n",
    "sentences_df_female = sentences_df_baseline[sentences_df_baseline['gender']=='female']\n",
    "print(\"S metric: {}\".format(calculate_s_metric(sentences_df_male, sentences_df_female)))\n",
    "# print(\"Delta p metric: {}\".format(mean_absolute_difference(sentences_df_baseline,'entailment_prob')))\n",
    "# print(\"B metric: {}\".format(calculate_b_metric(sentences_df_baseline, 'entailment_prob')))\n",
    "\n",
    "# output_df, wp, wa, wn = output_distribution(sentences_df_baseline)\n",
    "# print(output_df)\n",
    "# print(\"FN score: {}\".format(fn_score(output_df, wp, wa, wn)))\n",
    "# print(\"NLI-coAl score: {}\".format(nli_coal_score_incompetence(output_df)))\n",
    "\n",
    "# Here expected answers aren't neutral so we can't use FN Score and NLI-coAL. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16623d2-cb89-410e-9784-174ccc13c054",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "comp550-final-project",
   "language": "python",
   "name": "comp550-final-project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
